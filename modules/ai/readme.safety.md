# 安全

## 1. 任务与指令

描述： 攻击者试图通过提示或操控输入来更改 AI 代理的指令或目标。

缓解措施： 执行验证检查和输入过滤，以检测潜在危险的提示，在它们被 AI 代理处理之前拦截。由于这类攻击通常需要频繁与代理交互，限制对话轮数也是防止此类攻击的有效方法。

## 2. 对关键系统的访问

描述： 如果 AI 代理可以访问存储敏感数据的系统和服务，攻击者可能会破坏代理与这些服务之间的通信。这可能是直接攻击，也可能是通过代理间接获取这些系统的信息。

缓解措施： AI 代理应仅在需要时访问相关系统，以防止此类攻击。代理与系统之间的通信应确保安全。实施身份验证和访问控制也是保护信息的有效手段。

## 3. 资源和服务过载

描述： AI 代理可以访问不同的工具和服务来完成任务。攻击者可能利用这一能力，通过代理发送大量请求来攻击这些服务，可能导致系统故障或高昂成本。

缓解措施： 实施策略以限制 AI 代理对服务的请求数量。限制对话轮数和请求次数也是防止此类攻击的另一种方法。

## 4. 知识库污染

描述： 这种攻击并不直接针对 AI 代理，而是针对代理将使用的知识库和其他服务。这可能包括篡改代理完成任务所需的数据或信息，导致代理向用户提供偏颇或意外的响应。

缓解措施： 定期验证 AI 代理在其工作流程中使用的数据。确保对这些数据的访问是安全的，并且只有受信任的人员才能更改，以避免此类攻击。

## 5. 连锁错误

描述： AI 代理依赖多种工具和服务来完成任务。攻击者引发的错误可能导致其他系统的故障，使攻击范围扩大且更难排查。

缓解措施： 一种避免方法是让 AI 代理在受限环境中运行，例如在 Docker 容器中执行任务，以防止直接系统攻击。创建回退机制和重试逻辑，以应对某些系统返回错误的情况，也是防止更大范围系统故障的有效手段。

- [building-trustworthy-agents](https://github.com/pengjinning/ai-agents-for-beginners/tree/main/translations/zh/06-building-trustworthy-agents)
